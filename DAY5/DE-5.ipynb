{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ab188-2d6c-479b-9704-7690514899fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit\n",
    "===========\n",
    "open-source framework - interactive webapplications for data science and ML Projects\n",
    "Interactive Widgets\n",
    "Deployment\n",
    "No html/js/css required\n",
    "\n",
    "import streamlit\n",
    "streamlit.function() -> UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95879ce-dbe3-4ffa-89fb-97daba69965a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run s1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdaf111e-e85f-473a-b059-2ef27b12a3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run s2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb37441-234b-47bb-8651-4f100b517178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run s3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "949ef02d-4818-4181-bb0a-bf5a523519d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run s4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4293f998-fc77-40e4-b5cf-59d5047c6a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run s5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6af06d7c-1204-4e86-b19f-60206650d806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run s6.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a631d390-4ede-452b-ac3b-c27bade1e6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run s7.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d2f0a1-d70c-4eb2-a67d-9c348ba15358",
   "metadata": {},
   "outputs": [],
   "source": [
    "student --enquire PG Course -------\n",
    "    |____friend1 -- CS      ------  1\n",
    "    |____teacher -- Civil        \n",
    "    |____Family1 -- Physics  \n",
    "    |____Family2 -- CS              1      CS = 3\n",
    "    |____friend2 -- Mech\n",
    "    |____teacher -- CS              1   "
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd88c6a5-ebbb-45aa-98e8-8f4d677c8fdd",
   "metadata": {},
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['species'] = iris.target\n",
    "\n",
    "# Train a RandomForest model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(df.iloc[:, :-1], df['species'])\n",
    "\n",
    "# Sidebar input sliders\n",
    "st.sidebar.title('Input Features')\n",
    "sepal_length = st.sidebar.slider('Sepal length (cm)', float(df['sepal length (cm)'].min()), float(df['sepal length (cm)'].max()))\n",
    "sepal_width = st.sidebar.slider('Sepal width (cm)', float(df['sepal width (cm)'].min()), float(df['sepal width (cm)'].max()))\n",
    "petal_length = st.sidebar.slider('Petal length (cm)', float(df['petal length (cm)'].min()), float(df['petal length (cm)'].max()))\n",
    "petal_width = st.sidebar.slider('Petal width (cm)', float(df['petal width (cm)'].min()), float(df['petal width (cm)'].max()))\n",
    "\n",
    "# Prepare input data\n",
    "input_data = [[sepal_length, sepal_width, petal_length, petal_width]]\n",
    "\n",
    "# Prediction\n",
    "prediction = model.predict(input_data)\n",
    "predicted_species = iris.target_names[prediction[0]]\n",
    "\n",
    "# Display result\n",
    "st.write(\"### Prediction\")\n",
    "st.write(f\"The predicted species is: **{predicted_species}**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9548e5e7-90ea-4414-a15d-5c2079a17feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run randomForestML.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458cc49-2c46-43ba-9e2c-aadbde3d61bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "st.title(\"Linear Regression Demo\")\n",
    "\n",
    "# Sidebar inputs\n",
    "st.sidebar.header(\"Data Settings\")\n",
    "n_points = st.sidebar.slider(\"Number of data points\", 10, 200, 50)\n",
    "noise_level = st.sidebar.slider(\"Noise level\", 0.0, 10.0, 2.0)\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X = np.linspace(0, 10, n_points)\n",
    "y = 3 * X + 7 + np.random.randn(n_points) * noise_level\n",
    "\n",
    "# Reshape X for sklearn\n",
    "X_reshaped = X.reshape(-1, 1)\n",
    "\n",
    "# Fit linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_reshaped, y)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_reshaped)\n",
    "\n",
    "# Show model parameters\n",
    "st.write(f\"**Slope (Coefficient):** {model.coef_[0]:.2f}\")\n",
    "st.write(f\"**Intercept:** {model.intercept_:.2f}\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X, y, label=\"Data\", color=\"blue\")\n",
    "ax.plot(X, y_pred, color=\"red\", label=\"Regression Line\")\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.legend()\n",
    "st.pyplot(fig)\n",
    "\n",
    "# Show data table\n",
    "df = pd.DataFrame({\"X\": X, \"y\": y, \"Predicted y\": y_pred})\n",
    "st.dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02037b0e-9009-4106-81a0-04e626f4da0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run linearRegression_strem.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e0b033d-1c86-4f59-8302-79ec12248725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run app_search_engine.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdc5ff6-e82b-4834-8e8b-593176f5e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Example\n",
    "#--------------------\n",
    "# File: Sqlite3_Ollama.py \n",
    "import sqlite3\n",
    "import ollama\n",
    "\n",
    "# 1. Set up SQLite database and store sample documents\n",
    "def setup_database():\n",
    "    conn = sqlite3.connect('myfile.db')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS documents (\n",
    "                        id INTEGER PRIMARY KEY,\n",
    "                        content TEXT\n",
    "                      )''')\n",
    "    sample_documents = [\n",
    "        (\"The first letter is alpha.\",),\n",
    "        (\"The second letter is beta.\",)\n",
    "    ]\n",
    "    cursor.executemany(\"INSERT INTO documents (content) VALUES (?)\", sample_documents)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "setup_database()\n",
    "\n",
    "# 2. Function to retrieve documents based on query\n",
    "def retrieve_documents(query):\n",
    "    conn = sqlite3.connect('myfile.db')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT content FROM documents WHERE content LIKE ?\", ('%' + query + '%',))\n",
    "    results = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [result[0] for result in results]\n",
    "\n",
    "# 3. Function to generate a response using Ollama\n",
    "def generate_response(query, documents):\n",
    "    context = \"\\n\".join(documents)\n",
    "    prompt = f\"Query: {query}\\n\\nContext:\\n{context}\\n\\nResponse:\"\n",
    "    response = ollama.chat(model=\"gemma:2b\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response['message']\n",
    "\n",
    "# 4. Complete flow: Query input, document retrieval, and response generation\n",
    "def handle_query(query):\n",
    "    retrieved_docs = retrieve_documents(query)\n",
    "    if retrieved_docs:\n",
    "        response = generate_response(query, retrieved_docs)\n",
    "        return response\n",
    "    else:\n",
    "        return \"No relevant documents found.\"\n",
    "\n",
    "# Test the whole process with a sample query\n",
    "query = \"first\"\n",
    "response = handle_query(query)\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479fa6cb-abdb-42fc-8a38-815b9d4e3d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Folder_Search.py\n",
    "import streamlit as st\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "os.environ['GROQ_API_KEY']=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "\n",
    "# Init Streamlit\n",
    "st.set_page_config(page_title=\"Search Engine with LangChain Agents\")\n",
    "st.title(\"🔍 LangChain-Powered Search Engine (Docs + Web)\")\n",
    "st.write(\"Ask questions, and the agent will choose between local documents or web search to answer.\")\n",
    "\n",
    "# Upload documents\n",
    "if \"vectorstore\" not in st.session_state:\n",
    "    with st.spinner(\"Loading documents and building vector index...\"):\n",
    "        loader = PyPDFDirectoryLoader(\"docs\")\n",
    "        documents = loader.load()\n",
    "\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        split_docs = splitter.split_documents(documents)\n",
    "\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        st.session_state.vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "# Setup tools\n",
    "retriever_tool = Tool(\n",
    "    name=\"DocumentSearch\",\n",
    "    func=st.session_state.vectorstore.as_retriever().get_relevant_documents,\n",
    "    description=\"Use this to search through uploaded research papers.\"\n",
    ")\n",
    "\n",
    "web_search_tool = Tool(\n",
    "    name=\"WebSearch\",\n",
    "    func=DuckDuckGoSearchRun().run,\n",
    "    description=\"Use this to search the web for recent or general info.\"\n",
    ")\n",
    "\n",
    "tools = [retriever_tool, web_search_tool]\n",
    "\n",
    "# Choose model (OpenAI, Groq, Ollama)\n",
    "# llm = ChatOpenAI(temperature=0)  # Replace with ChatGroq(...) or ChatOllama(...) if desired\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "agent_executor = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Query input\n",
    "query = st.text_input(\"Ask a question (e.g., 'What does the research say about Llama 3?')\")\n",
    "\n",
    "if query:\n",
    "    with st.spinner(\"Thinking...\"):\n",
    "        answer = agent_executor.run(query)\n",
    "        st.success(\"Answer:\")\n",
    "        st.write(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
