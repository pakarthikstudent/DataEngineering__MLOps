{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83e\uddea Customer 360 Data Platform with Spark + Delta Lake + AWS S3\n", "This notebook demonstrates how to build a simple Customer 360 data pipeline using Delta Lake on AWS S3.\n", "\n", "We'll simulate three layers:\n", "- **Bronze**: Raw data ingestion\n", "- **Silver**: Cleaned and enriched data\n", "- **Gold**: Final Customer 360 dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 Spark Session with Delta and S3 access\n", "from pyspark.sql import SparkSession\n", "from delta import configure_spark_with_delta_pip\n", "\n", "builder = SparkSession.builder \\\n", "    .appName(\"Customer360\") \\\n", "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n", "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n", "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"s3.amazonaws.com\") \\\n", "    .config(\"spark.hadoop.fs.s3a.access.key\", \"<YOUR_ACCESS_KEY>\") \\\n", "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"<YOUR_SECRET_KEY>\") \\\n", "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n", "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n", "\n", "spark = configure_spark_with_delta_pip(builder).getOrCreate()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\udd47 Step 1: Ingest CRM and Web Log data (Bronze layer)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["crm_df = spark.createDataFrame([\n", "    (1, \"Alice\", \"alice@example.com\"),\n", "    (2, \"Bob\", \"bob@example.com\")\n", "], [\"customer_id\", \"name\", \"email\"])\n", "\n", "web_df = spark.createDataFrame([\n", "    (1, \"page_view\", \"2025-07-01\"),\n", "    (1, \"purchase\", \"2025-07-02\"),\n", "    (2, \"page_view\", \"2025-07-01\")\n", "], [\"customer_id\", \"event\", \"event_date\"])\n", "\n", "# Save raw data to Bronze layer\n", "crm_df.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://mybucket/bronze/crm/\")\n", "web_df.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://mybucket/bronze/web_logs/\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\udd48 Step 2: Clean and standardize (Silver layer)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["clean_crm = spark.read.format(\"delta\").load(\"s3a://mybucket/bronze/crm/\")\n", "clean_web = spark.read.format(\"delta\").load(\"s3a://mybucket/bronze/web_logs/\")\n", "\n", "clean_web = clean_web.filter(\"event_date IS NOT NULL\")\n", "\n", "clean_crm.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://mybucket/silver/crm/\")\n", "clean_web.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://mybucket/silver/web_logs/\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\udd49 Step 3: Join and create Customer 360 (Gold layer)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark.sql.functions import count\n", "\n", "crm = spark.read.format(\"delta\").load(\"s3a://mybucket/silver/crm/\")\n", "web = spark.read.format(\"delta\").load(\"s3a://mybucket/silver/web_logs/\")\n", "\n", "activity = web.groupBy(\"customer_id\").agg(count(\"*\").alias(\"total_events\"))\n", "customer_360 = crm.join(activity, on=\"customer_id\", how=\"left\").fillna(0)\n", "\n", "customer_360.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://mybucket/gold/customer_360/\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udd0d Step 4: Read final Customer 360 table"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = spark.read.format(\"delta\").load(\"s3a://mybucket/gold/customer_360/\")\n", "df.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}