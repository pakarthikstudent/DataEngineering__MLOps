{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83c\udfde\ufe0f Local Data Lake with Delta Lake & PySpark\n", "\n", "This notebook shows how to use Delta Lake on your local Windows machine using your filesystem as a data lake."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udce6 Install necessary packages (run once)\n", "!pip install pyspark delta-spark"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2699\ufe0f Configure Spark Session with Delta Lake\n", "from pyspark.sql import SparkSession\n", "from delta import configure_spark_with_delta_pip\n", "\n", "builder = SparkSession.builder \\\n", "    .appName(\"Local Delta Lake Example\") \\\n", "    .master(\"local[*]\") \\\n", "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n", "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n", "\n", "spark = configure_spark_with_delta_pip(builder).getOrCreate()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udcc1 Define local data lake path (adjust to your system)\n", "lake_path = \"file:///C:/data-lake/users\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udcdd Create sample data and write as Delta table\n", "data = [(1, \"Alice\"), (2, \"Bob\"), (3, \"Cathy\")]\n", "df = spark.createDataFrame(data, [\"id\", \"name\"])\n", "df.write.format(\"delta\").mode(\"overwrite\").save(lake_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udcd6 Read data from local Delta table\n", "df_read = spark.read.format(\"delta\").load(lake_path)\n", "df_read.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83e\uddea Time travel: view older version (if any)\n", "# Example: spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(lake_path).show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83e\uddf9 Stop Spark session when done\n", "spark.stop()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}